{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prabirdeb/FriendLE/blob/main/FriendLE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All report files, evaluation files and student file must be set to view anyone with the link**"
      ],
      "metadata": {
        "id": "aZaHkglJa-Vf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy1IUxDsmgxF"
      },
      "source": [
        "1. Error shall be managed through try else block\n",
        "\n",
        "\n",
        "Note:\n",
        "1. Student shall not change the subject names and headings\n",
        "2. Student must share the file to view anyone with the link\n",
        "3. No filter shall be selected"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import re\n",
        "\n",
        "# # Text processing\n",
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "# from nltk.corpus import stopwords\n",
        "# from nltk.stem.snowball import SnowballStemmer\n",
        "# import string\n",
        "\n",
        "# # Data reading\n",
        "# import pkgutil   # provides binary data\n",
        "# from io import StringIO # for binary to high level data conversion\n",
        "\n",
        "# # For showing image along with answer\n",
        "# import urllib.request\n",
        "# from PIL import Image"
      ],
      "metadata": {
        "id": "ggK7jF4uIZHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZL3dXRl5p7y"
      },
      "outputs": [],
      "source": [
        "# Writing helper functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# writing text pre-processing function\n",
        "def text_process(text):\n",
        "    text = text.lower()    # converting to lowercase\n",
        "    import string\n",
        "    text =[char for char in text if char not in string.punctuation] # removing punctuations\n",
        "    text=''.join(text) \n",
        "\n",
        "    import nltk\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    pos_tagged_tokens = nltk.pos_tag(tokens)\n",
        "\n",
        "    list_of_verbs = []\n",
        "    for i in range(len(pos_tagged_tokens)):\n",
        "      if pos_tagged_tokens[i][1].startswith('V'):\n",
        "        list_of_verbs.append(pos_tagged_tokens[i][0])\n",
        "    \n",
        "    nltk.download('stopwords')\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    stopwords.extend(list_of_verbs)\n",
        "\n",
        "    text=[word for word in text.split() if word not in stopwords] # removing stopwords and verbs\n",
        "    text=' '.join(text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "WcbG7HPgHD6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQSpPCN95umy"
      },
      "outputs": [],
      "source": [
        "# Writing main function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c=0"
      ],
      "metadata": {
        "id": "YvNB1ZH2D9_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_blank(id, subject):\n",
        "  try:\n",
        "    # Importing libraries\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    # global c\n",
        "    # Reading student data as pandas df\n",
        "    gsheetid = \"1g1uWDGjJ1aGRXtJVkISj9qwq-DJmnzTS\"\n",
        "    sheet_name = \"Sheet1\" # Student should not change the sheet name\n",
        "\n",
        "    # Converting google sheet to csv\n",
        "    gsheet_url = \"https://docs.google.com/spreadsheets/d/{}/gviz/tq?tqx=out:csv&sheet={}\".format(gsheetid, sheet_name)\n",
        "\n",
        "    # Creating student data df\n",
        "    student_data = pd.read_csv(gsheet_url)\n",
        "\n",
        "    # Creating individual student df\n",
        "    # Getting google sheet id\n",
        "    gsheetid = student_data[(student_data[\"ID\"]==id)][\"Concept_link\"].values[0].replace(\"https://docs.google.com/spreadsheets/d/\",\"\").split(\"/\")[0]\n",
        "    sheet_name = \"Concepts\" # Student should not change the sheet name\n",
        "\n",
        "    # Converting google sheet to csv\n",
        "    gsheet_url = \"https://docs.google.com/spreadsheets/d/{}/gviz/tq?tqx=out:csv&sheet={}\".format(gsheetid, sheet_name)\n",
        "\n",
        "    # Creating individual student data df\n",
        "    individual_student_data = pd.read_csv(gsheet_url)\n",
        "    individual_student_data = individual_student_data[(individual_student_data[\"Class\"]==student_data[(student_data[\"ID\"]==id)][\"Class\"].values[0])]\n",
        "\n",
        "    # Getting the document for the subject\n",
        "    sub=subject.title() # Converting to title case\n",
        "    subject_data=individual_student_data[(individual_student_data.Subjects==sub)]\n",
        "\n",
        "    relevant_features=['Concept-1', 'Concept-2', 'Concept-3', 'Concept-4', 'Concept-5',\n",
        "    'Concept-6', 'Concept-7', 'Concept-8', 'Concept-9', 'Concept-10',\n",
        "    'Concept-11', 'Concept-12', 'Concept-13', 'Concept-14', 'Concept-15',\n",
        "    'Concept-16', 'Concept-17', 'Concept-18', 'Concept-19', 'Concept-20']\n",
        "\n",
        "    subject_data=subject_data[relevant_features]\n",
        "    # Creating documents with all individual cell\n",
        "    subject_data=pd.DataFrame(subject_data.values.flatten(), columns=['documents'])\n",
        "\n",
        "    # Removing null value rows\n",
        "    subject_data.dropna(inplace=True) \n",
        "\n",
        "    # There are many documents with only newline character. Removing those rows\n",
        "    subject_data=subject_data[(subject_data['documents']!='\\n')]\n",
        "    subject_data=subject_data[(subject_data['documents']!='\\n\\n')]\n",
        "\n",
        "    # Removing all the rows with no data and reseting index \n",
        "    subject_data=subject_data[(subject_data['documents']!='No data')].reset_index()\n",
        "\n",
        "    subject_data.drop('index',axis=1, inplace=True)\n",
        "\n",
        "    if subject_data.shape[0]!=0:\n",
        "      # Random selection of concept\n",
        "      index_lst=list(subject_data.index)\n",
        "      import random\n",
        "      random.shuffle(index_lst)\n",
        "      original_text=subject_data.documents[index_lst[0]]\n",
        "\n",
        "      # Generating answer and question\n",
        "      # Random selection of question\n",
        "      import random\n",
        "      text=text_process(original_text)\n",
        "      if len(text.split())>0:\n",
        "        lst=text.split()\n",
        "        random.shuffle(lst)\n",
        "        ans=lst[0]\n",
        "        \n",
        "        ans_index=original_text.lower().split().index(ans)\n",
        "        original_text=original_text.split()\n",
        "        original_text[ans_index]=\"_____\"\n",
        "        ques=\" \".join(original_text)\n",
        "        # Question answer checking     \n",
        "        result1=ques\n",
        "        student_ans= \"mango\" #input(\"Write answer for the blank: \").lower()\n",
        "\n",
        "        if student_ans==ans:\n",
        "          # c=c+10\n",
        "          result2=\"Awesome! Absolutely correct\" # \\nYour total score: {c}\n",
        "        else:\n",
        "          # c=c-10\n",
        "          result2=\"Incorrect. Please revise the chapter.\\nCorrect answer is:\" # \\nYour total score: {c}\n",
        "      else:\n",
        "        result2=\"Ask question again. Concept found is very poor in strength:(\"\n",
        "      \n",
        "    else:\n",
        "      result2=\"You have no concept record for this subject\"\n",
        "  except:\n",
        "    result2=\"Please provide correct id and subject name\"\n",
        "  \n",
        "  return result1\n"
      ],
      "metadata": {
        "id": "0JdLaZkj0VwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit Project\n",
        "import streamlit as st # All the text cell will be displayed after this import statement\n",
        "\n",
        "st.title(\"Welcome to FriendLE Preparation\")\n",
        "\n",
        "id = st.number_input(\"Your ID\")\n",
        "\n",
        "subject = st.text_input(\"Subject\")\n",
        "subject=subject.title() # .title() is used to get the input question string\n",
        "\n",
        "result = fill_blank(id, subject)\n",
        "\n",
        "if(st.button('Ask Me')):   # display the ans when the submit button is clicked\n",
        "  st.success(result)"
      ],
      "metadata": {
        "id": "E7B-MCj4NU7H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}